<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>mostlymaths.net  | Databricks&#39; Delta Lake: high on ACID</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.86.0" />
    
    
    <META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">
    
    
    <link rel="preload" href="webfonts/reforma/Reforma1969/Reforma1969-Gris.woff2" as="font" type="font/woff2" crossorigin="anonymous">
    
    <link rel="preload" href="webfonts/reforma/Reforma1969/Reforma1969-BlancaItalica.woff2" as="font" type="font/woff2" crossorigin="anonymous">
    
    <link rel="preload" href="webfonts/reforma/Reforma1969/Reforma1969-Negra.woff2" as="font" type="font/woff2" crossorigin="anonymous">
    
    <link rel="preload" href="webfonts/reforma/Reforma1969/Reforma1969-Blanca.woff2" as="font" type="font/woff2" crossorigin="anonymous">
    
    <link rel="preload" href="webfonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin="anonymous">
    
    <link rel="preload" href="webfonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
    
    
    
    <link href="https://mostlymaths.net/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    
    <link rel="stylesheet" href="https://mostlymaths.net/byrne-caps/stylesheet.css">
    
    <link rel="stylesheet" href="https://mostlymaths.net/css/custom.css">
    
    <link rel="stylesheet" href="https://mostlymaths.net/webfonts/monoid.css">
    
    <link rel="stylesheet" href="https://mostlymaths.net/webfonts/nymphette.css">
    
    <link rel="stylesheet" href="https://mostlymaths.net/webfonts/reforma/reforma.css">
    

    
    
    <link rel="stylesheet" href="https://mostlymaths.net/css/all.min.854b4170d20fc6d7b6d5b8397ce94907561dc83cd449bdf0ef523ab393181898.css">
        

    
    
    

    

    <meta property="og:title" content="Databricks&#39; Delta Lake: high on ACID" />
<meta property="og:description" content="After reading the Snowflake paper, I got curious about how similar engines work. Also, as I mentioned in that article, I like knowing how the data sausage is made. So, here I will summarise the Delta Lake paper by Databricks." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mostlymaths.net/2020/10/delta-lake.html/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-10-12T18:30:33+02:00" />
<meta property="article:modified_time" content="2020-10-12T18:30:33+02:00" />

<meta itemprop="name" content="Databricks&#39; Delta Lake: high on ACID">
<meta itemprop="description" content="After reading the Snowflake paper, I got curious about how similar engines work. Also, as I mentioned in that article, I like knowing how the data sausage is made. So, here I will summarise the Delta Lake paper by Databricks."><meta itemprop="datePublished" content="2020-10-12T18:30:33+02:00" />
<meta itemprop="dateModified" content="2020-10-12T18:30:33+02:00" />
<meta itemprop="wordCount" content="3024">
<meta itemprop="keywords" content="Data,Databricks,Data Papers,Apache Spark," />

    
    
      
    
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image:src" content="/images/dresser/wide13.jpg"/>
<meta name="twitter:card" content="summary"/>


<meta name="twitter:domain" content="mostlymaths.net"/>
<meta name="twitter:creator" content="@berenguel"/>



<meta name="twitter:title" content="Databricks&#39; Delta Lake: high on ACID"/>
<meta name="twitter:description" content="After reading the Snowflake paper, I got curious about how similar engines work. Also, as I mentioned in that article, I like knowing how the data sausage is made. So, here I will summarise the Delta Lake paper by Databricks."/>

<meta name="author" content="Ruben Berenguel">
    
      
         
         <script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "99eeca521698412394b263e9f6d28662"}'></script>
      
    
  </head>

  <body class="ma0 reforma bg-near-white">

    


  
  
    
  
<header class="cover bg-top" style="max-height: 250px;background-image: url('https://mostlymaths.net///images/dresser/wide13.jpg');">
    <div class="pb1-m pb1-l bg-black-60">
      <nav class="pv1 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://mostlymaths.net/" class="f3 fw2 hover-white no-underline white-90 dib">
      mostlymaths.net
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
              <a class="hover-white no-underline white-90" href="https://mostlymaths.net/search/" title=" page">
                  <i class='fas fa-search'> </i>
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
              <a class="hover-white no-underline white-90" href="https://mostlymaths.net/sitemap/" title=" page">
                  <i class='fas fa-map'> </i>
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
              <a class="hover-white no-underline white-90" href="https://mostlymaths.net/pages/about/" title="about page">
                  about
            </a>
          </li>
          
        </ul>
      
    </div>
  </div>
</nav>

      <div class="tc-l pv3 ph3 ph4-ns">
        
          
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      

    <article class="flex-l flex-wrap justify-between mw8 center ph3">
  
    <header class="mt4 w-100">
        <h1 class="fw1 mb1 f1">Databricks&#39; Delta Lake: high on ACID</h1>
        
    <section class="w-60 mt3">
        <span class="fw2 f3 i ">Delta Lake: High-Performance ACID Table Storage over Cloud Object Stores</span>
    </section>
    
        
        <time class="f6 mt4 dib tracked" datetime="2020-10-12T18:30:33&#43;02:00">October 12, 2020</time>
      
      
      &nbsp;&nbsp;&nbsp;
      <span class="fw1 mv1 dib tracked i" style="font-size: 0.8rem;"> 15 minutes read</span>
      <span class="fw1 mv1 dib tracked i" style="font-size: 0.8rem;"> | 3024 words</span>
      
      <span class="f6 mv1 dib tracked" style="font-size: 0.8rem;"> by <a href="https://mostlymaths.net">Ruben Berenguel</a></span> 
    </header>

    
    
    <section class="nested-copy-line-height lh-copy f4 nested-links nested-img mid-gray pr4-l w-75-l justify dropcap"><p>After <a href="https://mostlymaths.net/2020/10/snowflake.html/">reading the Snowflake paper</a>, I got curious about how similar engines work. Also, as I mentioned in that article, I <em>like knowing how the data sausage is made</em>. So, here I will summarise the <a href="https://databricks.com/wp-content/uploads/2020/08/p975-armbrust.pdf">Delta Lake paper by Databricks</a>.</p>
<figure class="fig-full"><img src="https://mostlymaths.net/images/dresser/wide13.jpg"/>
</figure>
<ul>
<li><a href="#what-is-delta-lake">What is Delta Lake?</a></li>
<li><a href="#problems-and-benefits-with-cloud-object-stores">Problems and benefits with cloud object stores</a></li>
<li><a href="#storage-format-and-performance-implications">Storage format and performance implications</a></li>
<li><a href="#storage-access-protocols">Storage Access Protocols</a>
<ul>
<li><a href="#read-protocol">Read protocol</a></li>
<li><a href="#write-protocol">Write protocol</a></li>
</ul>
</li>
<li><a href="#impact-of-the-protocol">Impact of the protocol</a></li>
<li><a href="#known-limitations">Known limitations</a></li>
<li><a href="#wrap-up">Wrap-up</a></li>
</ul>
<h3 id="what-is-delta-lake">What is Delta Lake?</h3>
<p><a href="https://delta.io">Delta Lake</a> is an internal product by <a href="https://databricks.com">Databricks</a>, open sourced at the North American 2019 <a href="https://databricks.com/sparkaisummit">Spark Summit</a>. Its goal is to offer ACID (<em>Atomicity, Consistency, Isolation, Durability</em>, a set of properties databases offer) guarantees over cloud-based object storage (that is Amazon’s S3 for instance) as well as optimise Spark workloads. How? Stay tuned and keep reading.</p>
<p>It also enables read-only access from <a href="https://hive.apache.org">Hive</a>, <a href="https://prestodb.io">Presto</a>, <a href="https://aws.amazon.com/athena/">AWS Athena</a>, <a href="https://aws.amazon.com/redshift/">AWS Redshift</a>, <a href="https://www.snowflake.com">Snowflake</a> and more. That is, these systems can read data stored <em>as</em> Delta. Write from CDC (<em>change-data-capture</em>) systems like <a href="https://mostlymaths.net/2020/10/snowflake.html/">Fivetran</a>, <a href="https://www.informatica.com">Informatica</a>, <a href="https://www.qlik.com/us">Qlik</a> and <a href="https://www.talend.com">Talend</a> is also available.</p>
<p>It also has sped up access to BI tools via a new offering <a href="https://databricks.com/blog/2020/06/24/introducing-delta-engine.html">Delta Engine</a>, a proprietary full-stage, vectorised native execution engine. There are no technical details on this paper or anywhere else (except for a presentation I’m yet to watch) about Delta Engine. I wonder if it has some relationship with <a href="https://www.cs.purdue.edu/homes/rompf/papers/essertel-osdi18.pdf">Flare</a>.</p>
<p>Note: it is interesting that reading from Delta is achieved via the <a href="https://docs.databricks.com/delta/presto-integration.html">symlink manifest file</a> offered by Hive, which defines which files from the folder <em>should be visible to the reading system</em>.</p>
<div class="sb sb-2">
  <hr class="section-break-2" />
</div>
<h3 id="problems-and-benefits-with-cloud-object-stores">Problems and benefits with cloud object stores</h3>
<div class="note ">
<span class='scaps ' style="display: inline-block;">
  Notation
</span> 
<span class='note-body ' style="display: inline-block;">
<p>I will use <code>OS</code> to mean <strong>Object Store</strong> from now on, since they are mentioned constantly. There will be no mention of <em>operating systems</em> in this post, so all appearances of <code>OS</code> mean <em>object store</em>.</p>
</span>
</div>
<p>Why would anyone want to use cloud <code>OS</code>s to store their data? Obviously, for cost reasons. <code>OS</code>s are the cheapest storage available, and at scale. Imagine the alternative, having your own <a href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html">HDFS</a> cluster, with its <code>NameNode</code> and all the <code>DataNodes</code> required to store this data. If you run the numbers, you’ll see how large the difference in cost is, as well as the difference in management required. There are some catches, especially when comparing against HDFS. Latency in HDFS is pretty low, (at least for a decently configured cluster against any <code>OS</code>) which makes querying <code>OS</code>s slower than querying HDFS or using a proper database system. Overcoming this latency is one of the fundamental goals of Delta Lake (and of Snowflake, but that was the subject of another post).</p>
<p>Using <code>OS</code> has several tradeoffs to balance. Parallelism, sequential I/O, network bandwidth, all need to be considered to optimise usage. A simple example is full utilisation of network bandwidth: peak throughput in <code>OS</code> is around 50/100 MB/s, but most compute instances (the ones reading this data from the network) have 10 GB network cards or virtual cards. Without adequate parallelisation of reads you have a lot of bandwidth idle.</p>
<figure class="fig-tall right"><img src="https://mostlymaths.net/images/dresser/tall5.jpg"/>
</figure>
<p><code>OS</code>s don’t work as real filesystems, even if they look like they do. They actually work as key-value stores, where a key looks like a path. For example, if you have ever used <a href="https://redis.io">Redis</a> (or <a href="https://www.aerospike.com">Aerospike</a>), they follow more or less the same approach. Note that this is not the case for HDFS, which actually works like a real filesystem: this is what the FS part of HDFS stands for. This key-centeredness of <code>OS</code>s explains one of the main issues with using them: <code>LIST</code> operations, where you request a set or range of keys, are costly (unless you request things in a very specific way).</p>
<p>To overcome this, you may need to parallelise listing. Databricks (not Delta Lake, but Databricks’ version of Apache Spark) goes one step further, and worker nodes in Spark jobs issue <code>LIST</code> operations themselves. One of the advantages of Delta is not needing to issue <code>LIST</code>: that is already a large win.</p>
<p>Another issue, there are no generic cheap rename operation in <code>OS</code>s, neither are updates to object content available. If you need to update a line in the middle of a file, you need to rewrite the whole file. This makes mutability really hard to handle.</p>
<p>Each <code>OS</code> has its consistency model, and they get complex. All of them are eventually consistent, but the details of what happens right after a write operation can vary wildly (read-after-write is basically where many concurrency issues appear, think of the classic bank account deposit/withdrawal situation). No <code>OS</code> is consistent across several keys, though.</p>
<p>There are some obvious approaches when storing relational data in an <code>OS</code>. You want to be able to load data sequentially and with good compression. Why good compression? This needs further explanation.</p>
<figure class="fig30 left"><img src="https://mostlymaths.net/images/dresser/square6.jpg"/>
</figure>
<p>Due to the speed of network vs speed of compression, you’d rather spend CPU time decompressing: see <a href="https://www.blosc.org/docs/StarvingCPUs-CISE-2010.pdf">this article about Blosc</a> for some details. To maximise compression while enabling sequentiality, you need to choose a columnar format, like <a href="https://parquet.apache.org">Parquet</a> or <a href="https://orc.apache.org">ORC</a>. This has the additional advantage of using two formats with headers and footers with additional metadata, which act like partial zone maps (although you’d have to request them for each file, adding latency).</p>
<p>You want to have large files to compensate for network latency, since requesting many small files means you are handshaking too much as well as requesting many parts of files that are not data (headers, metadata).  But not too large, since deletes/updates require rewriting the whole file and you don’t want to rewrite large files.</p>
<p>You should use some partitioning scheme, like Hive’s filename partitioning. Sadly, partitioning schemes and <code>OS</code>s together don’t offer isolation nor atomicity, so you’d end with C and D only. Rolling back is hard, too, since versioning in <code>OS</code> does not map correctly to what a database roll back would require.</p>
<p>There are several existing (if you count Delta) approaches to using <code>OS</code>s to store relational data. The most common is the <em>directory of files</em>, something similar to Hive or <a href="https://hbase.apache.org">HBase</a>. On its own, there will be no atomicity and only eventual consistency. Given the slow metadata and listing capabilities, you end up with poor performance. You also lose any management (and auditing) capabilities unless you add them somehow.</p>
<p>Alternatively, you can have a <em>custom storage</em> based on <code>OS</code>. This is what Snowflake does. In this case, all I/O needs to pass through a metadata service (that is the <a href="https://mostlymaths.net/2020/10/snowflake.html/#cloud-services-layer">Cloud Layer in Snowflake</a>), adding latency to each query. Since the engine is custom, you’d need engineering work to connect to other systems, unless the storage and engine were open source based or the company offered them already. And you are tied to this particular vendor for a long, long time. Note that Hive is an open-source implementation of this approach, although it comes with its issues.</p>
<p>Finally, you can use the Delta approach: <em>metadata stored in <code>OS</code>s</em>. <a href="https://hudi.apache.org">Apache Hudi</a> and <a href="https://iceberg.apache.org">Apache Iceberg</a> are two open-source implementations that were concurrently tackling this problem while Delta Lake was being developed. They don’t necessarily benefit from the advantages of Delta Lake, some of which will be detailed later.</p>
<figure class="fig-full"><img src="https://mostlymaths.net/images/dresser/wide11.jpg"/>
</figure>
<h3 id="storage-format-and-performance-implications">Storage format and performance implications</h3>
<p>Delta stores data using Parquet, a format that is familiar to anyone in the data space. Columnar, with good compression and performance. The layout in the <code>OS</code> is using “folders” following Hive naming scheme for partitioning (like <code>year=2020</code>). Individual files are named using <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">GUID</a> (Globally Unique Identifier).</p>
<p>The bulk of the ACID transaction control is handled via a write-ahead log, stored in the folder <code>_delta_log</code> in the <code>OS</code>. The log is formed of transaction-recording JSON files, zero-padded and incrementally numbered. Occasionally there will be checkpointing log files, where several previous logs are coalesced.</p>
<p>Each JSON file contains a record of an array of actions that have been applied to the data in the table:</p>
<ul>
<li><strong>Change metadata</strong>: The metadata record contains the schema, column names, partitioning columns… The first record will always contain this. Note that this is very interesting information if you want to keep a catalog up to date or write your metadata engine: you only need to read this small JSON file.</li>
<li><strong>Add/Remove file</strong>: This is the fundamental action. Used when adding data or removing/updating data. When this action is recorded, statistics of the new file (minimum, maximum, etc) are added to the metadata section.</li>
<li><strong>Protocol evolution</strong>: This is internal for Delta, to know which version of the library can load these files.</li>
<li><strong>Adding provenance</strong>: To store information about who made the changes to the file. For auditing.</li>
<li><strong>Update application transaction ID</strong>: Stores information about which application has written this. Especially useful for streaming, to enable exactly once for user applications (and used internally for Spark Streaming). This goes into the field <code>txn</code> (I will mention this field again later).</li>
</ul>
<figure class="fig30 left"><img src="https://mostlymaths.net/images/dresser/square3.jpg"/>
</figure>
<p>During checkpointing log files are squashed together, writing new files on the <code>OS</code>. This acts like a form of materialization, where the records define a set of operations forming a view (an isolated one) based on several files, and the checkpoint materializes it in a new set of files. The only records left in the checkpoint are the transaction information, protocol change and metadata changes. All add/remove get lost, like in a squash commit in Git. By default, Delta checkpoints every 10 transactions, but the user can either configure or trigger checkpointing manually (with the <code>OPTIMIZE</code> SQL extension).</p>
<p>Checkpointing and change recording allows for efficient time travel and rollback. This is handled with the SQL extensions <code>AS OF timestamp</code> and <code>VERSION AS OF commit_id</code>. These can be used to see the table at time X or at record id X respectively.</p>
<p>Since whom changed what is also stored, there is a pretty good level of audit logging built into the system, via the <em>provenance</em> action.</p>
<p>By storing metadata information in separate files, there is no need to issue any <code>LIST</code> commands for data files (possibly millions), only for transaction record files (dozens). Schema evolution is relatively easy: since the schema is stored in the records, many schema changes can be acted on transactionally and some can even be compacted (column drops for instance). There is no detail about how column additions are handled, although I imagine that the Delta connector is more lenient than the Spark Parquet reader (which would fail for non-existing columns when a query plan demands them). Some form of <em>null if not present</em> needs to be offered in this case.</p>
<p>Databricks’ own Delta Lake uses <a href="https://en.wikipedia.org/wiki/Z-order_curve">Z-Ordering</a> to optimise the storage (<em>Data layout optimisation</em>). You can even choose the ordering approach and columns via an SQL extension (<code>ZORDER BY</code>). If you use Databricks, you also get auto-optimise. There are no details about what this does, but it is not that hard to check most common query paths and automatically set the Z-Ordering to speed up those queries. There are no details either about how Databricks implements Z-Ordering internally, but from comments in the performance evaluation section of the paper, it’s not “fully” Z-Ordering. But close. For each column in the Z-index, the whole dataset is at least partially ordered, as in, each file contains a chunk of the ordered set. Then, each file will have reasonable min-max metadata field that allows skipping it when querying outside those ranges. Compare this <a href="https://cdn2.hubspot.net/hubfs/392937/Whitepaper/WP/interleaved_keys_v12_1.pdf">with Redshift’s interleaved indices</a> (this PDF from <a href="https://chartio.com">Chartio</a> also talks about zone maps and is an excellent resource).</p>
<div class="note update">
  <span class="note-date">
    added on 2020-10-31
  </span>
<span class='scaps ' style="display: inline-block;">
  Z-Order information
</span> 
<span class='note-body ' style="display: inline-block;">
<p>Thanks to <a href="https://twitter.com/jmartinezvila">Josep Martínez Vilà</a> for giving me two Databricks-related Z-order links:</p>
<ul>
<li><a href="https://engineering.salesforce.com/boost-delta-lake-performance-with-data-skipping-and-z-order-75c7e6c59133">Boost Delta Lake Performance with Data Skipping and Z-Order (SalesForce Engineering)</a></li>
<li><a href="https://databricks.com/blog/2018/07/31/processing-petabytes-of-data-in-seconds-with-databricks-delta.html">Processing Petabytes of Data in Seconds with Databricks Delta</a></li>
</ul>
</span>
</div>
<div class="sb sb-2">
  <hr class="section-break-2" />
</div>
<h3 id="storage-access-protocols">Storage Access Protocols</h3>
<p>The access protocol is the foundation to enable ACID transactions. Reads and writes are handled differently, since the problems presented are also of different kinds. It is important to keep in mind that transaction records (the JSON file names) are serial.</p>
<h4 id="read-protocol">Read protocol</h4>
<figure class="fig30 right"><img src="https://mostlymaths.net/images/dresser/square5.jpg"/>
</figure>
<p>Reads are isolated either via snapshot isolation or due to the serializability of the record logs. Transaction isolation is at the table level. Given that files are immutable, once files are read they can be efficiently cached locally in worker nodes until there are metadata changes. The protocol for a read is as follows:</p>
<ol>
<li>First read the <code>_last_checkpoint</code> object, and if it exists use it to find the latest record ID to read.</li>
<li>Issue a <code>LIST</code> request for a prefix based on the latest record checkpoint ID or starting at 0. With this, the current state of the table can be reconstructed. Eventual consistency can make this <code>LIST</code> fail, returning non-contiguous records (skipping a few). The client reader then knows to wait for the intermediate results to be available, since they need to exist.</li>
<li>The current state of the table is reconstructed from checkpoints and/or actions. Reading all these (Parquet files for the data and JSON records for additional metadata) will be done in parallel.</li>
<li>Metadata statistics from each file (coming from the JSON records) will be used to determine which files are relevant for the current query.</li>
<li>Data is read (possibly in parallel) from the <code>OS</code>. Due to the eventual consistency, some workers may not see the objects they have to access. They will keep retrying until they are present.</li>
</ol>
<p>Note that with this scheme, the clear weak point is with being sure the latest record (or checkpoint) is present and not eventually present. This is handled by the write protocol below.</p>
<h4 id="write-protocol">Write protocol</h4>
<ol>
<li>Find a recent log record ID using the first 2 steps of the read protocol. This finds record <code>r</code> and the write step will create record <code>r+1</code>.</li>
<li>Read the required data as in the read protocol, to reconstruct the state of the table.</li>
<li>Create any new files the transaction needs to create (object names will be GUIDs). This may be done in parallel.</li>
<li>Attempt to write the transaction log record <code>r+1</code>, if no other client has done so (note that this is where things get interesting/tricky: this needs to be done atomically). If the transaction fails it can be retried, possibly reusing the data already written in Parquet.</li>
<li>Optionally, checkpoint and make <code>_last_checkpoint</code> reference <code>r+1</code>.</li>
</ol>
<p>Step 4 depends on the cloud <code>OS</code> implementation. Google Cloud Storage and Azure Blob Store support atomic put-if-absent, which solves this issue. S3 does not have this property, and Databricks (their internal offering) has a lightweight coordination service that makes sure only one client can record for this ID (which makes it the same you’d have in the <em>custom engine</em> scenario, although only applies to write operations, not read operations). In the open-source version, all writes going through the same driver get guaranteed different log record ids. That is not a great solution if you use more than one driver/job writing to the same place, but to be fair if you do you deserve whatever happens. If you use HDFS or Azure Data Lake Storage, Delta will use atomic renames to rename a temporary written record file to the final one.</p>
<h3 id="impact-of-the-protocol">Impact of the protocol</h3>
<p>The need to keep record logs and fight with the eventual consistency of the <code>OS</code> reduces the transaction rate Delta Lake can handle. Step 4 in the write step is the limiting factor: the need to wait for the latency of put-if-absent. The rate mentioned in the paper is “several transactions per second”. There is no further qualification of this several, but we can assume it’s less than 20-30 (otherwise you get into the “dozens” area).</p>
<p>Crucially though, the paper says that even for streaming this transaction level is enough. This is because Delta Lake is optimised for streaming ingest and consume. It uses compaction of small writes transactionally, which readers don’t see (you can keep reading old files while another job is creating a compaction on new files with a posterior record log). This is what allows efficient <code>UPSERT/DELETE/MERGE</code> operations. Readers can keep reading the “old” files while background processes are modifying files. It effectively offers snapshot isolation.</p>
<p>It uses the <code>txn</code> field to handle exactly once semantics (I’m not exactly sure how they handle this, I’d need to review the code to be sure). Since records have increasing identifiers, it is easy to read from the tail of the table in streaming systems.</p>
<h3 id="known-limitations">Known limitations</h3>
<p>These are the limitations identified in the paper:</p>
<ul>
<li>Table transactions are at the level of a table. This is a reasonable decision to take, since handling transactions across tables causes a lot of contention (and potentially, locks).</li>
<li>For streaming, the limiting factor is the latency of the underlying <code>OS</code>. There is not a lot to be handled here.</li>
<li>Except the min/max per column added to metadata, there are no other secondary indexes. There is a working prototype according to the paper of <a href="https://www.postgresql.org/docs/9.6/bloom.html">Bloom indices</a>, <a href="https://mostlymaths.net/2020/10/snowflake.html/">something you can find also in Snowflake</a>.</li>
</ul>
<figure class="fig-full"><img src="https://mostlymaths.net/images/dresser/wide1.jpg"/>
</figure>
<h3 id="wrap-up">Wrap-up</h3>
<p>I expected a bit more detail in this paper, to be fair. Although it is detailed enough to know <em>how</em> it works, it really doesn’t scratch the itch of knowing the nitty-gritty details of some decisions and choices. Particularly, no mention of how Z-Ordering is achieved, or what are the implications of checkpointing. Let me explain.</p>
<p>One of the main selling points from Databricks in the past two years has been GDPR right-to-remove capabilities. In your classical <code>OS</code> data lake, a removal request implies:</p>
<ol>
<li>find all files with that identifier,</li>
<li>write files without that identifier,</li>
<li>rename the new to the old or whatever you need to make it consistent.</li>
</ol>
<p>Databricks argues that this is expensive due to the reading, writing and handling. I agree on the fact that handling this process is a pain, but I still don’t see where we get a particular speed-up in this case when using Delta. Compaction is not free, some worker node that you are paying for will eventually run steps 1-3. Automatically, yes, but still will cost compute power.</p>
<p>The speed up promises, though, seem realistic. Immutability without needing to issue <code>LIST</code> requests are a big speed up for caching, and zone maps/Z-ordering should be a significant speed up for many work scenarios. After all, the fastest way to scan a file is being aware the data is not there and not even loading it.</p>
<hr>
<div class="note ">
<span class='scaps smallText' style="display: inline-block;">
  All images in this post are from:
</span> 
<span class='note-body smallText' style="display: inline-block;">
<p><a href="https://archive.org/details/Studiesdesign00Dres/page/n173/mode/2up">Christopher Dresser&rsquo;s <em>Studies in Design</em></a></p>
</span>
</div><hr/>
        <ul class="pa0">
  
   <li class="list" style="display:inline;">
     <a href="https://mostlymaths.net/tags/data" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Data</a>
   </li>
  
   <li class="list" style="display:inline;">
     <a href="https://mostlymaths.net/tags/databricks" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Databricks</a>
   </li>
  
   <li class="list" style="display:inline;">
     <a href="https://mostlymaths.net/tags/data-papers" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Data Papers</a>
   </li>
  
   <li class="list" style="display:inline;">
     <a href="https://mostlymaths.net/tags/apache-spark" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Apache Spark</a>
   </li>
  
</ul>
<div class="mt6">
            
            
        </div>
    </section>
<canvas id='map'></canvas>
<script src="https://mostlymaths.net/js/pagemap-1.2.0.min.js"></script>
<script src="https://mostlymaths.net/js/pagemap-settings.js"></script>

<aside class="w-25-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links rounded-6">
    <p class="fw1 f4 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
           <a href="https://mostlymaths.net/2020/11/rdd.html/">The RDD paper: introducing the Spark general purpose framework</a>
       </li>
	     
	     <li  class="mb2">
           <a href="https://mostlymaths.net/2021/01/lakehouse.html/">Lakehouse: It&#39;s like Delta Lake, but not really</a>
       </li>
	     
	     <li  class="mb2">
           <a href="https://mostlymaths.net/2020/10/databricks-jdbc.html/">Running SparkSQL on Databricks via Airflow&#39;s JDBC operator</a>
       </li>
	     
	     <li  class="mb2">
           <a href="https://mostlymaths.net/2021/03/spark-redshift-parquet-utf8.html/">UTF-8 Issues between AWS Redshift and Apache Spark when COPY PARQUET</a>
       </li>
	     
	     <li  class="mb2">
           <a href="https://mostlymaths.net/2021/01/hive.html/">Down memory lane: the Hive paper</a>
       </li>
	     
    </ul>
  </div>
  <div style="min-height: 3em;">
  </div></aside>
    
    </article>
    
    
    
    <script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "99eeca521698412394b263e9f6d28662"}'></script>
    

    </main>
    <footer class="bg-gray bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://mostlymaths.net/" >
    &copy; 2022 mostlymaths.net
  </a>
    <div>


<a href="https://www.facebook.com/mostlymaths/" target="_blank" class="link-transition facebook link dib z-999 pt3 pt0-l mr1" title="Facebook link" rel="noopener" aria-label="follow on Facebook——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://www.twitter.com/berenguel" target="_blank" class="link-transition twitter link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel="noopener" aria-label="follow on Twitter——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://www.instagram.com/mostlymaths/" target="_blank" class="link-transition instagram link dib z-999 pt3 pt0-l mr1" title="Instagram link" rel="noopener" aria-label="follow on Instagram——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M42.271,26.578v-0.006c0.502,0,1.005,0.01,1.508-0.002  c0.646-0.017,1.172-0.57,1.172-1.217c0-0.963,0-1.927,0-2.89c0-0.691-0.547-1.24-1.236-1.241c-0.961,0-1.922-0.001-2.883,0  c-0.688,0.001-1.236,0.552-1.236,1.243c-0.001,0.955-0.004,1.91,0.003,2.865c0.001,0.143,0.028,0.291,0.073,0.426  c0.173,0.508,0.639,0.82,1.209,0.823C41.344,26.579,41.808,26.578,42.271,26.578z M33,27.817c-3.384-0.002-6.135,2.721-6.182,6.089  c-0.049,3.46,2.72,6.201,6.04,6.272c3.454,0.074,6.248-2.686,6.321-6.043C39.254,30.675,36.462,27.815,33,27.817z M21.046,31.116  v0.082c0,4.515-0.001,9.03,0,13.545c0,0.649,0.562,1.208,1.212,1.208c7.16,0.001,14.319,0.001,21.479,0  c0.656,0,1.215-0.557,1.215-1.212c0.001-4.509,0-9.02,0-13.528v-0.094h-2.912c0.411,1.313,0.537,2.651,0.376,4.014  c-0.161,1.363-0.601,2.631-1.316,3.803s-1.644,2.145-2.779,2.918c-2.944,2.006-6.821,2.182-9.946,0.428  c-1.579-0.885-2.819-2.12-3.685-3.713c-1.289-2.373-1.495-4.865-0.739-7.451C22.983,31.116,22.021,31.116,21.046,31.116z   M45.205,49.255c0.159-0.026,0.318-0.049,0.475-0.083c1.246-0.265,2.264-1.304,2.508-2.557c0.025-0.137,0.045-0.273,0.067-0.409  V21.794c-0.021-0.133-0.04-0.268-0.065-0.401c-0.268-1.367-1.396-2.428-2.78-2.618c-0.058-0.007-0.113-0.02-0.17-0.03H20.761  c-0.147,0.027-0.296,0.047-0.441,0.08c-1.352,0.308-2.352,1.396-2.545,2.766c-0.008,0.057-0.02,0.114-0.029,0.171V46.24  c0.028,0.154,0.05,0.311,0.085,0.465c0.299,1.322,1.427,2.347,2.77,2.52c0.064,0.008,0.13,0.021,0.195,0.03H45.205z M33,64  C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>



<a href="https://linkedin.com/in/rberenguel" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/rberenguel" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




</div>
  </div>
</footer>

    

  <script src="https://mostlymaths.net/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
